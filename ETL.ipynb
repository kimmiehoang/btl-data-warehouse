{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "-c7V0Pi-6VFc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in c:\\users\\lenovo\\appdata\\roaming\\python\\python311\\site-packages (2.1.2)\n",
            "Requirement already satisfied: numpy<2,>=1.23.2 in c:\\python311\\lib\\site-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\lenovo\\appdata\\roaming\\python\\python311\\site-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\python311\\lib\\site-packages (from pandas) (2023.3.post1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in c:\\python311\\lib\\site-packages (from pandas) (2023.3)\n",
            "Requirement already satisfied: six>=1.5 in c:\\python311\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Ignoring invalid distribution ~ (c:\\python311\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~ (c:\\python311\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~ (c:\\python311\\lib\\site-packages)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pymysql in c:\\python311\\lib\\site-packages (1.1.1)\n",
            "Requirement already satisfied: sqlalchemy in c:\\python311\\lib\\site-packages (2.0.39)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in c:\\python311\\lib\\site-packages (from sqlalchemy) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in c:\\users\\lenovo\\appdata\\roaming\\python\\python311\\site-packages (from sqlalchemy) (4.12.2)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Ignoring invalid distribution ~ (c:\\python311\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~ (c:\\python311\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~ (c:\\python311\\lib\\site-packages)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: psycopg2-binary in c:\\python311\\lib\\site-packages (2.9.10)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Ignoring invalid distribution ~ (c:\\python311\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~ (c:\\python311\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~ (c:\\python311\\lib\\site-packages)\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas\n",
        "!pip install pymysql sqlalchemy\n",
        "!pip install psycopg2-binary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CFyT86QC6fRH",
        "outputId": "d7b84886-b8aa-4eb8-ee8e-be517707d35f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(                YNSM_NO   YNSM_CUST             ynsd_prod  ynsd_qty  \\\n",
              " 0  S2530030              A0566       PS05848DG54B046B1G01         1   \n",
              " 1  S2530030              A0566       PS05848DH68B046B1G01         1   \n",
              " 2  S2530030              A0566       PS05848DLH4B046B1G01         2   \n",
              " 3  S2530030              A0566       PS05848DH48B04519G01         2   \n",
              " 4  S2530030              A0566       PS05848DH48B0451BG01         2   \n",
              " \n",
              "     ynsd_amt    YN_DATE location  \n",
              " 0  477727.27  3/12/2025    north  \n",
              " 1  477727.27  3/12/2025    north  \n",
              " 2  477727.27  3/12/2025    north  \n",
              " 3  477727.27  3/12/2025    north  \n",
              " 4  477727.27  3/12/2025    north  ,\n",
              "           PS_NO         dd cus_no cur_id                prd_no  qty  \\\n",
              " 0  SA250312F012  3/12/2025  A0379    NaN  PS05310DB07000000F01   80   \n",
              " 1  SA250312F014  3/12/2025  A0379    NaN     SXV02529SCA001001  300   \n",
              " 2  SA250312F018  3/12/2025  A0379    NaN     SXV02529SCA003001  200   \n",
              " 3  SA250312F015  3/12/2025  A0379    NaN     SXV02529SCA001001  200   \n",
              " 4  SA250312F016  3/12/2025  A0379    NaN     SXV02529SCA001001  200   \n",
              " \n",
              "           amt location  \n",
              " 0  22581818.0    south  \n",
              " 1   9081818.0    south  \n",
              " 2   6054545.0    south  \n",
              " 3   6054545.0    south  \n",
              " 4   6054545.0    south  )"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "north_file_path = \"./data/Pos_north_vn_sales_data.csv\"\n",
        "south_file_path = \"./data/erp_south_sales_data_record.csv\"\n",
        "\n",
        "df_north = pd.read_csv(north_file_path)\n",
        "df_south = pd.read_csv(south_file_path)\n",
        "\n",
        "df_north[\"location\"] = \"north\"\n",
        "df_south[\"location\"] = \"south\"\n",
        "\n",
        "df_north.head(), df_south.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MTEKjzzF9iG1",
        "outputId": "bafd1523-96d2-42bd-8145-fd16ddce7732"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(               order_no customer_id            product_id  quantity  \\\n",
              " 0  S2530030              A0566       PS05848DG54B046B1G01         1   \n",
              " 1  S2530030              A0566       PS05848DH68B046B1G01         1   \n",
              " 2  S2530030              A0566       PS05848DLH4B046B1G01         2   \n",
              " 3  S2530030              A0566       PS05848DH48B04519G01         2   \n",
              " 4  S2530030              A0566       PS05848DH48B0451BG01         2   \n",
              " \n",
              "       amount       date location  \n",
              " 0  477727.27 2025-03-12    north  \n",
              " 1  477727.27 2025-03-12    north  \n",
              " 2  477727.27 2025-03-12    north  \n",
              " 3  477727.27 2025-03-12    north  \n",
              " 4  477727.27 2025-03-12    north  ,\n",
              "        order_no       date customer_id cur_id            product_id  quantity  \\\n",
              " 0  SA250312F012 2025-03-12       A0379    VND  PS05310DB07000000F01        80   \n",
              " 1  SA250312F014 2025-03-12       A0379    VND     SXV02529SCA001001       300   \n",
              " 2  SA250312F018 2025-03-12       A0379    VND     SXV02529SCA003001       200   \n",
              " 3  SA250312F015 2025-03-12       A0379    VND     SXV02529SCA001001       200   \n",
              " 4  SA250312F016 2025-03-12       A0379    VND     SXV02529SCA001001       200   \n",
              " \n",
              "        amount location  \n",
              " 0  22581818.0    south  \n",
              " 1   9081818.0    south  \n",
              " 2   6054545.0    south  \n",
              " 3   6054545.0    south  \n",
              " 4   6054545.0    south  )"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_north.rename(columns={\"YNSM_NO\": \"order_no\", \"YNSM_CUST\": \"customer_id\",\n",
        "                         \"ynsd_prod\": \"product_id\", \"ynsd_qty\": \"quantity\",\n",
        "                         \"ynsd_amt\": \"amount\", \"YN_DATE\": \"date\"}, inplace=True)\n",
        "\n",
        "df_south.rename(columns={\"PS_NO\": \"order_no\", \"cus_no\": \"customer_id\",\n",
        "                         \"prd_no\": \"product_id\", \"qty\": \"quantity\",\n",
        "                         \"amt\": \"amount\", \"dd\": \"date\"}, inplace=True)\n",
        "\n",
        "df_north[\"date\"] = pd.to_datetime(df_north[\"date\"], errors='coerce')\n",
        "df_south[\"date\"] = pd.to_datetime(df_south[\"date\"], errors='coerce')\n",
        "df_south[\"cur_id\"].fillna(\"VND\", inplace=True)\n",
        "\n",
        "df_north.head(), df_south.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "jbWXFaAWhrXI",
        "outputId": "c64b8928-6df9-47a7-94f3-f99192b14a97"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     exchange_date exchange_rate      Open      High       Low Vol. Change %\n",
            "1886    2025-03-01      25,530.0       NaN       NaN       NaN  NaN      NaN\n",
            "1887    2025-03-02      25,530.0       NaN       NaN       NaN  NaN      NaN\n",
            "1888    2025-03-03      25,575.0  25,554.0  25,617.5  25,548.0  NaN    0.18%\n",
            "1889    2025-03-04      25,540.0  25,580.0  25,596.5  25,555.0  NaN   -0.14%\n",
            "1890    2025-03-05      25,490.0  25,515.0  25,586.0  25,495.0  NaN   -0.20%\n",
            "1891    2025-03-06      25,485.0  25,450.0  25,516.5  25,430.0  NaN   -0.02%\n",
            "1892    2025-03-07      25,480.0  25,449.0  25,552.5  25,435.0  NaN   -0.02%\n",
            "1893    2025-03-08      25,480.0       NaN       NaN       NaN  NaN      NaN\n",
            "1894    2025-03-09      25,480.0       NaN       NaN       NaN  NaN      NaN\n",
            "1895    2025-03-10      25,525.0  25,515.0  25,568.5  25,510.0  NaN    0.18%\n",
            "1896    2025-03-11      25,450.0  25,512.5  25,520.0  25,462.0  NaN   -0.29%\n",
            "1897    2025-03-12      25,445.0  25,485.0  25,515.0  25,450.0  NaN   -0.02%\n",
            "1898    2025-03-13      25,490.0  25,475.0  25,512.5  25,465.0  NaN    0.18%\n",
            "1899    2025-03-14      25,500.0  25,520.0  25,532.5  25,465.0  NaN    0.04%\n",
            "1900    2025-03-15      25,500.0       NaN       NaN       NaN  NaN      NaN\n",
            "1901    2025-03-16      25,500.0       NaN       NaN       NaN  NaN      NaN\n",
            "1902    2025-03-17      25,510.0  25,520.0  25,586.0  25,475.0  NaN    0.04%\n",
            "1903    2025-03-18      25,510.0  25,525.0  25,550.0  25,520.0  NaN    0.00%\n",
            "1904    2025-03-19      25,535.0  25,530.0  25,550.0  25,525.0  NaN    0.10%\n",
            "1905    2025-03-20      25,555.0  25,535.0  25,555.0  25,545.0  NaN    0.08%\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "exchange_rate_file_path = \"./data/USD_VND_HistoricalData.csv\"\n",
        "\n",
        "df_exchange = pd.read_csv(exchange_rate_file_path)\n",
        "\n",
        "df_exchange[\"Date\"] = pd.to_datetime(df_exchange[\"Date\"], errors='coerce')\n",
        "\n",
        "df_exchange.rename(columns={\"Date\": \"exchange_date\", \"Price\": \"exchange_rate\"}, inplace=True)\n",
        "\n",
        "df_exchange = df_exchange.sort_values(by=\"exchange_date\")\n",
        "\n",
        "date_range = pd.date_range(start=df_exchange[\"exchange_date\"].min(), end=df_exchange[\"exchange_date\"].max(), freq=\"D\")\n",
        "\n",
        "df_full = pd.DataFrame(date_range, columns=[\"exchange_date\"])\n",
        "\n",
        "df_merged = df_full.merge(df_exchange, on=\"exchange_date\", how=\"left\")\n",
        "\n",
        "df_merged[\"exchange_rate\"] = df_merged[\"exchange_rate\"].ffill()\n",
        "\n",
        "print(df_merged.tail(20))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "LKemBsiqiNK7",
        "outputId": "17a85cfc-1cb3-4cae-f563-07872e8e7165"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>order_no</th>\n",
              "      <th>date</th>\n",
              "      <th>customer_id</th>\n",
              "      <th>cur_id</th>\n",
              "      <th>product_id</th>\n",
              "      <th>quantity</th>\n",
              "      <th>amount</th>\n",
              "      <th>location</th>\n",
              "      <th>exchange_rate</th>\n",
              "      <th>amount_vnd</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>SA250312F012</td>\n",
              "      <td>2025-03-12</td>\n",
              "      <td>A0379</td>\n",
              "      <td>VND</td>\n",
              "      <td>PS05310DB07000000F01</td>\n",
              "      <td>80</td>\n",
              "      <td>22581818.0</td>\n",
              "      <td>south</td>\n",
              "      <td>25445.0</td>\n",
              "      <td>22581818.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>SA250312F014</td>\n",
              "      <td>2025-03-12</td>\n",
              "      <td>A0379</td>\n",
              "      <td>VND</td>\n",
              "      <td>SXV02529SCA001001</td>\n",
              "      <td>300</td>\n",
              "      <td>9081818.0</td>\n",
              "      <td>south</td>\n",
              "      <td>25445.0</td>\n",
              "      <td>9081818.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>SA250312F018</td>\n",
              "      <td>2025-03-12</td>\n",
              "      <td>A0379</td>\n",
              "      <td>VND</td>\n",
              "      <td>SXV02529SCA003001</td>\n",
              "      <td>200</td>\n",
              "      <td>6054545.0</td>\n",
              "      <td>south</td>\n",
              "      <td>25445.0</td>\n",
              "      <td>6054545.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>SA250312F015</td>\n",
              "      <td>2025-03-12</td>\n",
              "      <td>A0379</td>\n",
              "      <td>VND</td>\n",
              "      <td>SXV02529SCA001001</td>\n",
              "      <td>200</td>\n",
              "      <td>6054545.0</td>\n",
              "      <td>south</td>\n",
              "      <td>25445.0</td>\n",
              "      <td>6054545.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>SA250312F016</td>\n",
              "      <td>2025-03-12</td>\n",
              "      <td>A0379</td>\n",
              "      <td>VND</td>\n",
              "      <td>SXV02529SCA001001</td>\n",
              "      <td>200</td>\n",
              "      <td>6054545.0</td>\n",
              "      <td>south</td>\n",
              "      <td>25445.0</td>\n",
              "      <td>6054545.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       order_no       date customer_id cur_id            product_id  quantity  \\\n",
              "0  SA250312F012 2025-03-12       A0379    VND  PS05310DB07000000F01        80   \n",
              "1  SA250312F014 2025-03-12       A0379    VND     SXV02529SCA001001       300   \n",
              "2  SA250312F018 2025-03-12       A0379    VND     SXV02529SCA003001       200   \n",
              "3  SA250312F015 2025-03-12       A0379    VND     SXV02529SCA001001       200   \n",
              "4  SA250312F016 2025-03-12       A0379    VND     SXV02529SCA001001       200   \n",
              "\n",
              "       amount location  exchange_rate  amount_vnd  \n",
              "0  22581818.0    south        25445.0  22581818.0  \n",
              "1   9081818.0    south        25445.0   9081818.0  \n",
              "2   6054545.0    south        25445.0   6054545.0  \n",
              "3   6054545.0    south        25445.0   6054545.0  \n",
              "4   6054545.0    south        25445.0   6054545.0  "
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_south = df_south.merge(df_merged[[\"exchange_date\", \"exchange_rate\"]], left_on=\"date\", right_on=\"exchange_date\", how=\"left\")\n",
        "\n",
        "df_south.drop(columns=[\"exchange_date\"], inplace=True)\n",
        "\n",
        "df_south[\"exchange_rate\"] = df_south[\"exchange_rate\"].fillna(\"0\")\n",
        "df_south[\"exchange_rate\"] = df_south[\"exchange_rate\"].str.replace(\",\", \"\").astype(float)\n",
        "\n",
        "df_south[\"amount_vnd\"] = df_south.apply(\n",
        "    lambda row: row[\"amount\"] if row[\"cur_id\"] == \"VND\" else row[\"amount\"] * row[\"exchange_rate\"], axis=1\n",
        ")\n",
        "\n",
        "df_south.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "yDhqv8UiBv8g",
        "outputId": "d93291f6-7844-4f79-ef80-6e9c43b4ef1b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>order_no</th>\n",
              "      <th>customer_id</th>\n",
              "      <th>product_id</th>\n",
              "      <th>quantity</th>\n",
              "      <th>amount</th>\n",
              "      <th>date</th>\n",
              "      <th>location</th>\n",
              "      <th>exchange_rate</th>\n",
              "      <th>cur_id</th>\n",
              "      <th>amount_vnd</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>S2530030</td>\n",
              "      <td>A0566</td>\n",
              "      <td>PS05848DG54B046B1G01</td>\n",
              "      <td>1</td>\n",
              "      <td>477727.27</td>\n",
              "      <td>2025-03-12</td>\n",
              "      <td>north</td>\n",
              "      <td>25445.0</td>\n",
              "      <td>VND</td>\n",
              "      <td>477727.27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>S2530030</td>\n",
              "      <td>A0566</td>\n",
              "      <td>PS05848DH68B046B1G01</td>\n",
              "      <td>1</td>\n",
              "      <td>477727.27</td>\n",
              "      <td>2025-03-12</td>\n",
              "      <td>north</td>\n",
              "      <td>25445.0</td>\n",
              "      <td>VND</td>\n",
              "      <td>477727.27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>S2530030</td>\n",
              "      <td>A0566</td>\n",
              "      <td>PS05848DLH4B046B1G01</td>\n",
              "      <td>2</td>\n",
              "      <td>477727.27</td>\n",
              "      <td>2025-03-12</td>\n",
              "      <td>north</td>\n",
              "      <td>25445.0</td>\n",
              "      <td>VND</td>\n",
              "      <td>477727.27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>S2530030</td>\n",
              "      <td>A0566</td>\n",
              "      <td>PS05848DH48B04519G01</td>\n",
              "      <td>2</td>\n",
              "      <td>477727.27</td>\n",
              "      <td>2025-03-12</td>\n",
              "      <td>north</td>\n",
              "      <td>25445.0</td>\n",
              "      <td>VND</td>\n",
              "      <td>477727.27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>S2530030</td>\n",
              "      <td>A0566</td>\n",
              "      <td>PS05848DH48B0451BG01</td>\n",
              "      <td>2</td>\n",
              "      <td>477727.27</td>\n",
              "      <td>2025-03-12</td>\n",
              "      <td>north</td>\n",
              "      <td>25445.0</td>\n",
              "      <td>VND</td>\n",
              "      <td>477727.27</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               order_no customer_id            product_id  quantity  \\\n",
              "0  S2530030              A0566       PS05848DG54B046B1G01         1   \n",
              "1  S2530030              A0566       PS05848DH68B046B1G01         1   \n",
              "2  S2530030              A0566       PS05848DLH4B046B1G01         2   \n",
              "3  S2530030              A0566       PS05848DH48B04519G01         2   \n",
              "4  S2530030              A0566       PS05848DH48B0451BG01         2   \n",
              "\n",
              "      amount       date location  exchange_rate cur_id  amount_vnd  \n",
              "0  477727.27 2025-03-12    north        25445.0    VND   477727.27  \n",
              "1  477727.27 2025-03-12    north        25445.0    VND   477727.27  \n",
              "2  477727.27 2025-03-12    north        25445.0    VND   477727.27  \n",
              "3  477727.27 2025-03-12    north        25445.0    VND   477727.27  \n",
              "4  477727.27 2025-03-12    north        25445.0    VND   477727.27  "
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_north = df_north.merge(df_merged[[\"exchange_date\", \"exchange_rate\"]], left_on=\"date\", right_on=\"exchange_date\", how=\"left\")\n",
        "\n",
        "df_north.drop(columns=[\"exchange_date\"], inplace=True)\n",
        "\n",
        "df_south[\"exchange_rate\"] = df_south[\"exchange_rate\"].fillna(\"0\")\n",
        "df_north[\"exchange_rate\"] = df_north[\"exchange_rate\"].str.replace(\",\", \"\").astype(float)\n",
        "\n",
        "df_north[\"cur_id\"] = \"VND\"\n",
        "\n",
        "df_north[\"amount_vnd\"] = df_north.apply(\n",
        "    lambda row: row[\"amount\"] if row[\"cur_id\"] == \"VND\" else row[\"amount\"] * row[\"exchange_rate\"], axis=1\n",
        ")\n",
        "\n",
        "df_north.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pX3H6Mr6NcT8",
        "outputId": "f5aafa49-0f91-453d-9539-6621e228b7f4"
      },
      "outputs": [],
      "source": [
        "from sqlalchemy import create_engine, text\n",
        "from urllib.parse import quote_plus\n",
        "\n",
        "DB_USER = \"dw_user\"\n",
        "DB_PASSWORD = quote_plus(\"dw_dss_BK@242\")\n",
        "DB_HOST = \"localhost\"\n",
        "DB_PORT = \"5433\"\n",
        "DB_NAME = \"sales_data_warehouse\"\n",
        "\n",
        "engine = create_engine(f\"postgresql://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{DB_NAME}\")\n",
        "\n",
        "df_all = pd.concat([df_north, df_south], ignore_index=True)\n",
        "\n",
        "#----------------------------------\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Transaction started.\n",
            "Loading dim_area...\n",
            "Processed 2 unique areas.\n",
            "Area map created.\n",
            "Loading dim_date...\n",
            "Processed 1553 unique dates.\n",
            "Date map created.\n",
            "Loading dim_currency...\n",
            "Processed 2 unique currencies.\n",
            "Currency map created.\n",
            "Loading dim_customer...\n",
            "Processed 672 unique customers.\n",
            "Customer map created.\n",
            "Loading dim_product...\n",
            "Processed 25272 unique products.\n",
            "Product map created.\n",
            "Loading fact_sales...\n",
            "Inserted 212606 rows into fact_sales.\n",
            "Transaction committed successfully.\n",
            "ETL process finished.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "df_all['date'] = pd.to_datetime(df_all['date']).dt.date \n",
        "df_all['location'] = df_all['location'].str.strip() \n",
        "df_all['customer_id'] = df_all['customer_id'].str.strip()\n",
        "df_all['product_id'] = df_all['product_id'].str.strip()\n",
        "df_all['cur_id'] = df_all['cur_id'].str.strip().str.upper() \n",
        "\n",
        "\n",
        "try:\n",
        "    with engine.connect() as connection:\n",
        "        with connection.begin():\n",
        "            print(\"Transaction started.\")\n",
        "\n",
        "            # === 1. Load DIM_AREA ===\n",
        "            print(\"Loading dim_area...\")\n",
        "            unique_locations = df_all[['location']].drop_duplicates().dropna()\n",
        "            if not unique_locations.empty:\n",
        "                area_data = unique_locations.to_dict(orient='records')\n",
        "                stmt_area = text(\"\"\"\n",
        "                    INSERT INTO dim_area (area_name)\n",
        "                    VALUES (:location)\n",
        "                    ON CONFLICT (area_name) DO NOTHING;\n",
        "                \"\"\")\n",
        "                connection.execute(stmt_area, area_data)\n",
        "                print(f\"Processed {len(area_data)} unique areas.\")\n",
        "\n",
        "            # Lấy mapping area_name -> area_id\n",
        "            area_map_result = connection.execute(text(\"SELECT area_name, area_id FROM dim_area;\"))\n",
        "            area_map = {row.area_name: row.area_id for row in area_map_result}\n",
        "            print(\"Area map created.\")\n",
        "\n",
        "            # === 2. Load DIM_DATE ===\n",
        "            print(\"Loading dim_date...\")\n",
        "            unique_dates_df = df_all[['date']].drop_duplicates().dropna()\n",
        "            if not unique_dates_df.empty:\n",
        "                date_data = []\n",
        "                for date_val in unique_dates_df['date']:\n",
        "                    date_data.append({\n",
        "                        'date': date_val,\n",
        "                        'year': date_val.year,\n",
        "                        'month': date_val.month,\n",
        "                        'day': date_val.day,\n",
        "                        'quarter': (date_val.month - 1) // 3 + 1\n",
        "                    })\n",
        "\n",
        "                stmt_date = text(\"\"\"\n",
        "                    INSERT INTO dim_date (date, year, month, day, quarter)\n",
        "                    VALUES (:date, :year, :month, :day, :quarter)\n",
        "                    ON CONFLICT (date) DO NOTHING;\n",
        "                \"\"\")\n",
        "                connection.execute(stmt_date, date_data)\n",
        "                print(f\"Processed {len(date_data)} unique dates.\")\n",
        "\n",
        "            # Lấy mapping date -> date_id\n",
        "            date_map_result = connection.execute(text(\"SELECT date, date_id FROM dim_date;\"))\n",
        "            date_map = {row.date: row.date_id for row in date_map_result}\n",
        "            print(\"Date map created.\")\n",
        "\n",
        "\n",
        "            # === 3. Load DIM_CURRENCY ===\n",
        "            print(\"Loading dim_currency...\")\n",
        "            unique_currencies = df_all[['cur_id']].drop_duplicates().dropna()\n",
        "            if not unique_currencies.empty:\n",
        "                currency_data = unique_currencies.rename(columns={'cur_id': 'cur_code'}).to_dict(orient='records')\n",
        "                stmt_currency = text(\"\"\"\n",
        "                    INSERT INTO dim_currency (cur_code)\n",
        "                    VALUES (:cur_code)\n",
        "                    ON CONFLICT (cur_code) DO NOTHING;\n",
        "                \"\"\")\n",
        "                connection.execute(stmt_currency, currency_data)\n",
        "                print(f\"Processed {len(currency_data)} unique currencies.\")\n",
        "\n",
        "            # Lấy mapping cur_code -> currency_id\n",
        "            currency_map_result = connection.execute(text(\"SELECT cur_code, currency_id FROM dim_currency;\"))\n",
        "            currency_map = {row.cur_code: row.currency_id for row in currency_map_result}\n",
        "            print(\"Currency map created.\")\n",
        "\n",
        "\n",
        "            # === 4. Load DIM_CUSTOMER ===\n",
        "            print(\"Loading dim_customer...\")\n",
        "            unique_customers = df_all[['customer_id', 'location']].drop_duplicates().dropna(subset=['customer_id'])\n",
        "            if not unique_customers.empty:\n",
        "                customer_data = []\n",
        "                for _, row in unique_customers.iterrows():\n",
        "                    area_id = area_map.get(row['location'])\n",
        "                    if area_id is None:\n",
        "                        print(f\"Warning: Skipping customer {row['customer_id']} due to unknown location '{row['location']}'.\")\n",
        "                        continue\n",
        "                    customer_data.append({\n",
        "                        'cus_no': row['customer_id'],\n",
        "                        'customer_name': row['customer_id'],\n",
        "                        'area_id': area_id\n",
        "                    })\n",
        "\n",
        "                if customer_data: \n",
        "                    stmt_customer = text(\"\"\"\n",
        "                        INSERT INTO dim_customer (cus_no, customer_name, area_id)\n",
        "                        VALUES (:cus_no, :customer_name, :area_id)\n",
        "                        ON CONFLICT (cus_no) DO NOTHING;\n",
        "                    \"\"\")\n",
        "                    connection.execute(stmt_customer, customer_data)\n",
        "                    print(f\"Processed {len(customer_data)} unique customers.\")\n",
        "\n",
        "            # Lấy mapping cus_no -> customer_id (PK của bảng)\n",
        "            customer_map_result = connection.execute(text(\"SELECT cus_no, customer_id FROM dim_customer;\"))\n",
        "            customer_map = {row.cus_no: row.customer_id for row in customer_map_result}\n",
        "            print(\"Customer map created.\")\n",
        "\n",
        "\n",
        "            # === 5. Load DIM_PRODUCT ===\n",
        "            print(\"Loading dim_product...\")\n",
        "            unique_products = df_all[['product_id']].drop_duplicates().dropna()\n",
        "            if not unique_products.empty:\n",
        "                product_data = []\n",
        "                for _, row in unique_products.iterrows():\n",
        "                    # Giả định tên = mã SP và các trường khác là NULL\n",
        "                    product_data.append({\n",
        "                        'prd_no': row['product_id'],\n",
        "                        'prd_name': row['product_id'], # Giả sử tên = mã SP\n",
        "                        'logo': None, 'model': None, 'std': None, 'color': None,\n",
        "                        'sqa': None, 'sqa_color': None, 'size_': None\n",
        "                    })\n",
        "\n",
        "                stmt_product = text(\"\"\"\n",
        "                    INSERT INTO dim_product\n",
        "                    (prd_no, prd_name, logo, model, std, color, sqa, sqa_color, size_)\n",
        "                    VALUES\n",
        "                    (:prd_no, :prd_name, :logo, :model, :std, :color, :sqa, :sqa_color, :size_)\n",
        "                    ON CONFLICT (prd_no) DO NOTHING;\n",
        "                \"\"\")\n",
        "                connection.execute(stmt_product, product_data)\n",
        "                print(f\"Processed {len(product_data)} unique products.\")\n",
        "\n",
        "            # Lấy mapping prd_no -> product_id (PK của bảng)\n",
        "            product_map_result = connection.execute(text(\"SELECT prd_no, product_id FROM dim_product;\"))\n",
        "            product_map = {row.prd_no: row.product_id for row in product_map_result}\n",
        "            print(\"Product map created.\")\n",
        "\n",
        "\n",
        "            # === 6. Load FACT_SALES ===\n",
        "            print(\"Loading fact_sales...\")\n",
        "            fact_data = []\n",
        "            processed_count = 0\n",
        "            skipped_count = 0\n",
        "\n",
        "            for index, row in df_all.iterrows():\n",
        "                # Lookup foreign keys\n",
        "                date_id = date_map.get(row['date'])\n",
        "                customer_id_fk = customer_map.get(row['customer_id'])\n",
        "                currency_id_fk = currency_map.get(row['cur_id'])\n",
        "                product_id_fk = product_map.get(row['product_id'])\n",
        "\n",
        "                # Validate foreign keys\n",
        "                if None in [date_id, customer_id_fk, currency_id_fk, product_id_fk]:\n",
        "                    skipped_count += 1\n",
        "                    continue\n",
        "\n",
        "\n",
        "                try:\n",
        "                    qty = int(row['quantity'])\n",
        "                    amt = float(row['amount'])\n",
        "                    amt_vnd = float(row['amount_vnd'])\n",
        "                    exchange_rate = float(row['exchange_rate'])\n",
        "                    if qty <= 0 or amt < 0 or exchange_rate <= 0:\n",
        "                         skipped_count += 1\n",
        "                         continue\n",
        "                except (ValueError, TypeError):\n",
        "                    skipped_count += 1\n",
        "                    continue\n",
        "\n",
        "\n",
        "                fact_data.append({\n",
        "                    'ps_no': row['order_no'],\n",
        "                    'date_id': date_id,\n",
        "                    'customer_id': customer_id_fk,\n",
        "                    'currency_id': currency_id_fk,\n",
        "                    'product_id': product_id_fk,\n",
        "                    'qty': qty,\n",
        "                    'amt': amt,\n",
        "                    'exchange_rate': exchange_rate,\n",
        "                    'amt_vnd': amt_vnd\n",
        "                })\n",
        "                processed_count += 1\n",
        "\n",
        "\n",
        "            if fact_data:\n",
        "                stmt_fact = text(\"\"\"\n",
        "                    INSERT INTO fact_sales\n",
        "                    (ps_no, date_id, customer_id, currency_id, product_id, qty, amt, exchange_rate, amt_vnd)\n",
        "                    VALUES\n",
        "                    (:ps_no, :date_id, :customer_id, :currency_id, :product_id, :qty, :amt, :exchange_rate, :amt_vnd);\n",
        "                \"\"\")\n",
        "\n",
        "                connection.execute(stmt_fact, fact_data)\n",
        "                print(f\"Inserted {len(fact_data)} rows into fact_sales.\")\n",
        "            else:\n",
        "                print(\"No valid data to insert into fact_sales.\")\n",
        "\n",
        "            if skipped_count > 0:\n",
        "                 print(f\"Total rows skipped due to missing FKs or invalid data: {skipped_count}\")\n",
        "\n",
        "        print(\"Transaction committed successfully.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"ETL failed. Transaction rolled back. Error: {e}\")\n",
        "\n",
        "finally:\n",
        "    print(\"ETL process finished.\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
